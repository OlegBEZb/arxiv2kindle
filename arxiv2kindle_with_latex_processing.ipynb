{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import needed libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For security reasons you need to create credentials.py file with dict like the following:  \n",
    "credentials = {  \n",
    "    'kindle_email': \"YOUR_EMAIL@kindle.com\",  \n",
    "    'your_gmail': \"YOUR_GMAIL@gmail.com\",  \n",
    "    'gmailpass': \"YOUR_PASS\",  \n",
    "               }  \n",
    "\n",
    "For creating gmailpass, please follow the [link](https://myaccount.google.com/apppasswords). Note that the account security settings will have to \"allow unsecure apps\" for permission to use the Gmail SMTP server with TLS.  \n",
    "\n",
    "**Do not forget to add this file to .gitignore**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Oleg\\\\Documents\\\\SourceTree\\\\arxiv2kindle'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for not to lose progress and for updating without reloading\n",
    "%autosave 180\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import requests\n",
    "import lxml.html as html\n",
    "import re\n",
    "import urllib\n",
    "import os, sys, subprocess, os.path\n",
    "import wget\n",
    "import glob\n",
    "import getpass\n",
    "import tempfile\n",
    "import tarfile\n",
    "\n",
    "from credentials import credentials\n",
    "\n",
    "# for sending msg\n",
    "import smtplib\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "## Inputr parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the needed_article_url can be an arxiv URL or any string containing \n",
    "# an arxiv ID.\n",
    "needed_article_url = \"http://arxiv.org/abs/1709.03856\"\n",
    "\n",
    "# paper settings (decrease width/height to increase font)\n",
    "landscape = False #horizontal\n",
    "width = \"4.2in\"\n",
    "height = \"6.55in\"\n",
    "margin = \"0.1in\"\n",
    "\n",
    "show_generated_pdf = True\n",
    "send = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kindle_email = credentials['kindle_email']\n",
    "your_gmail = credentials['your_gmail']\n",
    "gmailpass = credentials['gmailpass']\n",
    "\n",
    "# settings for latex geometry package:\n",
    "if landscape:\n",
    "    geom_settings = dict(paperwidth=width, paperheight=height, margin=margin)\n",
    "else:\n",
    "    geom_settings = dict(paperwidth=height, paperheight=width, margin=margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download archived arxiv archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv_id: 1709.03856\n",
      "arxiv_title: StarSpace: Embed All The Things!\n"
     ]
    }
   ],
   "source": [
    "arxiv_id = re.match(r'(http://.*?/)?(?P<id>\\d{4}\\.\\d{4,5}(v\\d{1,2})?)', needed_article_url).group('id')\n",
    "arxiv_abs = 'http://arxiv.org/abs/' + arxiv_id\n",
    "arxiv_pdf = 'http://arxiv.org/pdf/' + arxiv_id\n",
    "arxiv_pgtitle = html.fromstring(requests.get(arxiv_abs).text.encode('utf8')).xpath('/html/head/title/text()')[0]\n",
    "arxiv_title = re.sub(r'\\s+', ' ', re.sub(r'^\\[[^]]+\\]\\s*', '', arxiv_pgtitle), re.DOTALL)\n",
    "arxiv_title_scrubbed = re.sub('[^-_A-Za-z0-9]+', '_', arxiv_title, re.DOTALL)\n",
    "\n",
    "print('arxiv_id:', arxiv_id)\n",
    "print('arxiv_title:', arxiv_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0% [                                                                              ]     0 / 28399\r",
      " 28% [......................                                                        ]  8192 / 28399\r",
      " 57% [............................................                                  ] 16384 / 28399\r",
      " 86% [...................................................................           ] 24576 / 28399\r",
      "100% [..............................................................................] 28399 / 28399"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Oleg\\\\AppData\\\\Local\\\\Temp\\\\arxiv2kindle_gtvllduh\\\\StarSpace: Embed All The Things!.tar.gz'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create temporary directory\n",
    "d = tempfile.mkdtemp(prefix='arxiv2kindle_')\n",
    "\n",
    "archive_url = 'http://arxiv.org/e-print/' + arxiv_id\n",
    "\n",
    "# download tar.gz file and add file extension\n",
    "tar_filename = wget.download(archive_url, out=os.path.join(d, ''.join([arxiv_title, '.tar.gz'])))\n",
    "tar_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'found files with .tex extension'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Oleg\\\\AppData\\\\Local\\\\Temp\\\\arxiv2kindle_gtvllduh\\\\aaai_main.tex']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extract file contents\n",
    "os.chdir(d)\n",
    "tf = tarfile.open(tar_filename)\n",
    "tf.extractall()\n",
    "\n",
    "# find tex files\n",
    "texfiles = glob.glob(os.path.join(d, '*.tex'))\n",
    "display('found files with .tex extension', texfiles)\n",
    "\n",
    "for texfile in texfiles:\n",
    "    with open(texfile, 'r') as f:\n",
    "        src = f.readlines()\n",
    "    if 'documentclass' in src[0]:\n",
    "        print('correct file: ' + texfile)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter comments/newlines for easier debugging:\n",
    "src = [line for line in src if line[0] != '%' and len(line.strip()) > 0]\n",
    "\n",
    "# strip column stuff and stuff in documentclass line:\n",
    "src[0] = re.sub(r'\\b\\d+pt\\b', '', src[0]) # strip font size, ex. \"11pt\"\n",
    "src[0] = re.sub(r'\\b\\w+column\\b', '', src[0]) # strip \n",
    "src[0] = re.sub(r'\\b\\w+paper\\b', '', src[0]) # strip paper size, ex. \"letterpaper\" or \"a4paper\"\n",
    "src[0] = re.sub(r'(?<=\\[),', '', src[0]) # remove extraneous starting commas\n",
    "src[0] = re.sub(r',(?=[\\],])', '', src[0]) # remove extraneous middle/ending commas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find begin{document}:\n",
    "begindocs = [i for i, line in enumerate(src) if re.match(r'\\s*\\\\begin{document}', line)]\n",
    "\n",
    "try:\n",
    "    assert(len(begindocs) == 1)\n",
    "    src.insert(begindocs[0], '\\\\usepackage['+','.join(k+'='+v for k,v in geom_settings.items())+']{geometry}\\n')\n",
    "    src.insert(begindocs[0], '\\\\usepackage{times}\\n')\n",
    "    src.insert(begindocs[0], '\\\\pagestyle{empty}\\n')\n",
    "    if landscape:\n",
    "        src.insert(begindocs[0], '\\\\usepackage{pdflscape}\\n')\n",
    "except:\n",
    "    print('assert occured')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shrink figures to be at most the size of the page:\n",
    "for i in range(len(src)):\n",
    "    line = src[i]\n",
    "    m = re.search(r'\\\\includegraphics\\[width=([.\\d]+)\\\\(line|text)width\\]', line)\n",
    "    if m:\n",
    "        mul = m.group(1)\n",
    "        print(m)\n",
    "        src[i] = re.sub(r'\\\\includegraphics\\[width=([.\\d]+)\\\\(line|text)width\\]',\n",
    "                   r'\\\\includegraphics[width={mul}\\\\textwidth,height={mul}\\\\textheight,keepaspectratio]'.format(mul=mul),\n",
    "                   line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "пјЏ /\n",
      "480\n"
     ]
    }
   ],
   "source": [
    "# replace phrases or words fount in dictionary\n",
    "def normalize_by_dictionary(word, dictionary):\n",
    "    #print('normalizing', word)\n",
    "    \n",
    "    result = []\n",
    "    for word in word.split():\n",
    "        # if word is in uppercase\n",
    "        if word == word.upper():\n",
    "            if word.lower() in dictionary:\n",
    "                result.append(dictionary[word.lower()].upper())\n",
    "            else:\n",
    "                result.append(word)\n",
    "        else:\n",
    "            if word.lower() in dictionary:\n",
    "                result.append(dictionary[word.lower()])\n",
    "            else:\n",
    "                result.append(word)\n",
    "    \n",
    "    return \" \".join(result)\n",
    "\n",
    "\n",
    "latex_shit_mapping = {'пјЏ'.lower(): '/', 'In': 'in'}\n",
    "\n",
    "# replace this fucking latex shit\n",
    "for i in range(len(src)):\n",
    "    line = src[i].split()\n",
    "    for j, word in enumerate(line):\n",
    "#         if word.lower() in list(latex_shit_mapping.keys()):\n",
    "            normalized_word = normalize_by_dictionary(word, latex_shit_mapping)\n",
    "            if normalized_word != word:\n",
    "                print(word, normalized_word)\n",
    "                print(i)\n",
    "            src[i] = src[i].replace(word, normalized_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad_images []\n",
      "all files in article dif ['aaai.bst', 'aaai18.sty', 'aaai_main.bbl', 'aaai_main.tex', 'StarSpace']\n"
     ]
    }
   ],
   "source": [
    "# find non-compiling file extensions\n",
    "folder_files = os.listdir()\n",
    "bad_images = [file for file in folder_files if '.ps' in file or '.eps' in file]\n",
    "print('bad_images', bad_images)\n",
    "\n",
    "print('all files in article dif', os.listdir())\n",
    "\n",
    "# replace strange formats with pdf images\n",
    "for file in bad_images:\n",
    "    print(file)\n",
    "    filename = file.split('.')[0]\n",
    "    ! ps2pdf {file} {''.join([filename,'.pdf'])}\n",
    "    ! rm {file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Невозможно создать файл, так как он уже существует: 'C:\\\\Users\\\\Oleg\\\\AppData\\\\Local\\\\Temp\\\\arxiv2kindle_gtvllduh\\\\aaai_main.tex' -> 'C:\\\\Users\\\\Oleg\\\\AppData\\\\Local\\\\Temp\\\\arxiv2kindle_gtvllduh\\\\aaai_main.tex.bak'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-0428704484bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# src -> tex.bak and compile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtexfile\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.bak'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwritelines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Невозможно создать файл, так как он уже существует: 'C:\\\\Users\\\\Oleg\\\\AppData\\\\Local\\\\Temp\\\\arxiv2kindle_gtvllduh\\\\aaai_main.tex' -> 'C:\\\\Users\\\\Oleg\\\\AppData\\\\Local\\\\Temp\\\\arxiv2kindle_gtvllduh\\\\aaai_main.tex.bak'"
     ]
    }
   ],
   "source": [
    "# src -> tex.bak and compile\n",
    "os.rename(texfile, texfile+'.bak')\n",
    "with open(texfile, 'w') as f:\n",
    "    f.writelines(src)\n",
    "\n",
    "texout = !pdflatex {texfile} && pdflatex {texfile} && pdflatex {texfile}\n",
    "texout[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdffilename = texfile[:-4] + '.pdf'\n",
    "if sys.platform == 'darwin':\n",
    "    os.system('open ' + pdffilename)\n",
    "else:\n",
    "    os.system('xdg-open ' + pdffilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landscape False width 4.2in height 6.55in margin 0.1in\n"
     ]
    }
   ],
   "source": [
    "if show_generated_pdf:\n",
    "    # for displaying pdf\n",
    "    from wand.image import Image as WImage\n",
    "    \n",
    "    print('landscape', landscape, 'width', width, 'height', height, 'margin', margin)\n",
    "    #! {pdffilename}\n",
    "    i = 0\n",
    "    filename, file_extension = os.path.splitext(pdffilename)\n",
    "    while(1):\n",
    "        try:\n",
    "            filename_to_open = ''.join([filename, file_extension + '[{}]'.format(i)])\n",
    "            #print('filename_to_open', filename_to_open)\n",
    "            img = WImage(filename=filename_to_open)\n",
    "            display(img)\n",
    "            i += 1\n",
    "        except:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sending message from google mail to kindle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "msg = MIMEMultipart()\n",
    "pdf_part = MIMEApplication(open(texfile[:-4]+'.pdf', 'rb').read(), _subtype='pdf')\n",
    "pdf_part.add_header('Content-Disposition', 'attachment', filename=arxiv_title_scrubbed+\".pdf\")\n",
    "msg.attach(pdf_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if send:\n",
    "    with smtplib.SMTP_SSL('smtp.gmail.com') as server:\n",
    "        server.set_debuglevel(0)\n",
    "        server.ehlo()\n",
    "        #server.starttls()  \n",
    "        server.login(your_gmail, gmailpass)\n",
    "        server.sendmail(your_gmail, kindle_email, msg.as_string())\n",
    "        server.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
